{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyswlZo67KCX"
   },
   "outputs": [],
   "source": [
    "# ---------- visualizzo piu output a schermo insieme ------------------------------\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "#-------------------------- scelgo se usare CPU o GPU ------------------------------\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    " \n",
    "COMMIT = True \n",
    "SEED = 1234\n",
    "DATASET_SPLIT = 0.8\n",
    "img_h = 224\n",
    "img_w = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "classes = {\n",
    "        '0': 0,\n",
    "        '1': 1,\n",
    "        '2': 2,\n",
    "        '3': 3,\n",
    "        '4': 4,\n",
    "        '5': 5,\n",
    "        'apple': 6,\n",
    "        'baseball': 7,\n",
    "        'bench': 8,\n",
    "        'bike': 9,\n",
    "        'bird': 10,\n",
    "        'black': 11,\n",
    "        'blanket': 12,\n",
    "        'blue': 13,\n",
    "        'bone': 14,\n",
    "        'book': 15,\n",
    "        'boy': 16,\n",
    "        'brown': 17,\n",
    "        'cat': 18,\n",
    "        'chair': 19,\n",
    "        'couch': 20,\n",
    "        'dog': 21,\n",
    "        'floor': 22,\n",
    "        'food': 23,\n",
    "        'football': 24,\n",
    "        'girl': 25,\n",
    "        'grass': 26,\n",
    "        'gray': 27,\n",
    "        'green': 28,\n",
    "        'left': 29,\n",
    "        'log': 30,\n",
    "        'man': 31,\n",
    "        'monkey bars': 32,\n",
    "        'no': 33,\n",
    "        'nothing': 34,\n",
    "        'orange': 35,\n",
    "        'pie': 36,\n",
    "        'plant': 37,\n",
    "        'playing': 38,\n",
    "        'red': 39,\n",
    "        'right': 40,\n",
    "        'rug': 41,\n",
    "        'sandbox': 42,\n",
    "        'sitting': 43,\n",
    "        'sleeping': 44,\n",
    "        'soccer': 45,\n",
    "        'squirrel': 46,\n",
    "        'standing': 47,\n",
    "        'stool': 48,\n",
    "        'sunny': 49,\n",
    "        'table': 50,\n",
    "        'tree': 51,\n",
    "        'watermelon': 52,\n",
    "        'white': 53,\n",
    "        'wine': 54,\n",
    "        'woman': 55,\n",
    "        'yellow': 56,\n",
    "        'yes': 57\n",
    "}\n",
    "\n",
    "N_CLASSES = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSlN5coj7OQH",
    "outputId": "949f15e0-03d2-45a5-cfc5-0800bb83075f"
   },
   "outputs": [],
   "source": [
    "# percorsi\n",
    "train_json_path = cwd + '/VQA_Dataset/train_questions_annotations.json'\n",
    "test_json_path = cwd + '/VQA_Dataset/test_questions.json'\n",
    "imgs_path = cwd + '/VQA_Dataset/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J06ZU_QzQrde"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, answers_ID, image_name, train_input_questions, max_length, to_fit=True,\n",
    "                 batch_size=32, dim=(img_h, img_w), n_channels=3, n_classes=N_CLASSES, shuffle=False):\n",
    "        self.answers_ID = answers_ID\n",
    "        self.train_input_questions = train_input_questions\n",
    "        self.image_name = image_name\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.img_h = dim[0]\n",
    "        self.img_w = dim[1]\n",
    "        self.max_length = max_length\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_name) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X = self._generate_X(batch_indexes)\n",
    "        if self.to_fit:\n",
    "            # answers\n",
    "            Y = np.asarray([self.answers_ID[k] for k in batch_indexes])\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # salvo indici totali (globali)\n",
    "        self.indexes = np.arange(len(self.image_name))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _generate_X(self, batch_indexes):\n",
    "        imm = np.empty((self.batch_size, img_h, img_w, self.n_channels))\n",
    "        quest = np.empty((self.batch_size, self.max_length))\n",
    "        # i = indice batch   ID = indice globale --> creo abbinamenti domanda/immagine per il batch\n",
    "        for i, ID in enumerate(batch_indexes):\n",
    "            #ID dell'immagine\n",
    "            imm[i,] = self._load_image(self.image_name[ID], self.img_w, self.img_h)\n",
    "            #question: lista di id domande\n",
    "            quest[i,] = (self.train_input_questions[ID]).tolist()\n",
    "        X = [np.array(quest), np.array(imm)]\n",
    "        return X\n",
    "\n",
    "    def _load_image(self, image_name, img_w, img_h):\n",
    "        image = np.array(Image.open(os.path.join(imgs_path,image_name+'.png')).resize([img_h,img_w]))[:,:,:3]\n",
    "        #image = image/ 255.\n",
    "        image = preprocess_input(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzioni per estrarre dati\n",
    "\n",
    "def readTestJson(data):\n",
    "    key_list=list(data.keys())\n",
    "    image_IDs = []\n",
    "    questions = []\n",
    "    questionsID = []\n",
    "\n",
    "    for key in key_list:\n",
    "        image_IDs.append(data[key]['image_id'])\n",
    "        questionsID.append(key)\n",
    "        tmp_question = (data[key]['question'].replace(\"?\",\"\")).split(\" \")\n",
    "        questions.append(tmp_question)\n",
    "\n",
    "    return image_IDs, questionsID, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJzeq0_5Qrdk"
   },
   "outputs": [],
   "source": [
    "# creo vocabolario su train + test\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "with open(train_json_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(test_json_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "key_list=list(train_data.keys())\n",
    "image_IDs = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for key in key_list:\n",
    "    tmp = (train_data[key]['question'].replace(\"?\",\"\")).split(\" \")\n",
    "    image_IDs.append(train_data[key]['image_id'])\n",
    "    questions.append(tmp)\n",
    "    answers.append(classes[train_data[key]['answer']])\n",
    "\n",
    "all_questions_4Tokenizer = questions\n",
    "test_images, test_questionsID, test_questions = readTestJson(test_data)\n",
    "all_questions_4Tokenizer = all_questions_4Tokenizer + test_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_questions_4Tokenizer)      \n",
    "words_number = len(tokenizer.word_index) + 1\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(questions)\n",
    "all_sequences = tokenizer.texts_to_sequences(all_questions_4Tokenizer)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_questions)\n",
    "\n",
    "max_length = max(len(sequence) for sequence in all_sequences)\n",
    "train_input_questions = pad_sequences(train_sequences, maxlen=max_length)\n",
    "\n",
    "test_questions = pad_sequences(test_sequences, maxlen=max_length)\n",
    "\n",
    "# divido in training e validation\n",
    "perc = 0.8\n",
    "\n",
    "train_images = []\n",
    "train_questions = []\n",
    "train_answers = []\n",
    "valid_images = []\n",
    "valid_questions = []\n",
    "valid_answers = []\n",
    "\n",
    "for i in range(len(image_IDs)):\n",
    "    if (np.random.rand()) < perc:\n",
    "        train_images.append(image_IDs[i])\n",
    "        train_questions.append(train_input_questions[i])\n",
    "        train_answers.append(answers[i])\n",
    "    else:\n",
    "        valid_images.append(image_IDs[i])\n",
    "        valid_questions.append(train_input_questions[i])\n",
    "        valid_answers.append(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSiI4McVaGaa"
   },
   "outputs": [],
   "source": [
    "# data generators\n",
    "\n",
    "training_generator = DataGenerator(answers_ID = train_answers,\n",
    "                                   image_name = train_images,\n",
    "                                   train_input_questions = train_questions,\n",
    "                                   max_length = max_length,\n",
    "                                   to_fit=True,\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   dim=(img_h, img_w),\n",
    "                                   n_classes=N_CLASSES,\n",
    "                                   shuffle=True)\n",
    "\n",
    "validation_generator = DataGenerator(answers_ID = valid_answers,\n",
    "                                     image_name = valid_images,\n",
    "                                     train_input_questions = valid_questions,\n",
    "                                     max_length = max_length,\n",
    "                                     to_fit = True,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     dim=(img_h, img_w),\n",
    "                                     n_classes=N_CLASSES,\n",
    "                                     shuffle=False)\n",
    "\n",
    "test_generator = DataGenerator(answers_ID = None,\n",
    "                               image_name = test_images,\n",
    "                               train_input_questions = test_questions,\n",
    "                               max_length = max_length,\n",
    "                               to_fit=False,\n",
    "                               batch_size=1,\n",
    "                               dim=(img_h, img_w),\n",
    "                               n_classes=N_CLASSES,\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo il modello\n",
    "\n",
    "INPUT_SIZE_MERGE = 256\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(input_shape=(img_h, img_w, 3), include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# modello immagine\n",
    "vision_model = tf.keras.models.Sequential()\n",
    "vision_model.add(base_model)\n",
    "vision_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "vision_model.add(tf.keras.layers.Dense(INPUT_SIZE_MERGE))\n",
    "image_input = tf.keras.layers.Input(shape=(img_h, img_w, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "# modello testo\n",
    "question_input = tf.keras.layers.Input(shape=[max_length])\n",
    "embedded_question = tf.keras.layers.Embedding(input_dim=words_number, output_dim=256, input_length=max_length)(question_input)\n",
    "encoded_question = tf.keras.layers.LSTM(units=INPUT_SIZE_MERGE)(embedded_question)\n",
    "\n",
    "# modello finale (immagine + testo)\n",
    "merged = tf.keras.layers.concatenate([encoded_question, encoded_image])\n",
    "output = tf.keras.layers.Dense(len(classes), activation='softmax')(merged)\n",
    "vqa_model = tf.keras.models.Model(inputs=[question_input, image_input], outputs=output)\n",
    "\n",
    "load_weights = True \n",
    "if load_weights:\n",
    "    model_name = \"VQA\" \n",
    "    model_dir = os.path.join(cwd, \"model\")\n",
    "    vqa_model.load_weights(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BXaWbgoQrd7"
   },
   "outputs": [],
   "source": [
    "#-------- classe per cambiare lr ----------------------\n",
    "class CLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, schedule):\n",
    "        super(CLR, self).__init__()\n",
    "        self.schedule = schedule\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('non hai settato lr')\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjBI2CfYQrd8"
   },
   "outputs": [],
   "source": [
    "#---------------- definisco callbacks ------------------------------------\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    callbacks.append(es_callback)\n",
    "    \n",
    "#--------------------------- lookup table per lr (standard)-------------\n",
    "LUT_STD = []\n",
    "#------------------- funzione per passare lr ---------------------------\n",
    "def get_lr_std(epoch, lr):\n",
    "    if epoch < LUT_STD[0][0]:\n",
    "        return LUT_STD[0][1]\n",
    "    elif epoch > LUT_STD[len(LUT_STD)-1][0]:\n",
    "        return LUT_STD[len(LUT_STD)-1][1]\n",
    "    for i in range(len(LUT_STD)):\n",
    "        if epoch == LUT_STD[i][0]:\n",
    "            print(\"\\nnuovo lr: \"+str(LUT_STD[i][1]))\n",
    "            return LUT_STD[i][1]\n",
    "    return lr\n",
    "\n",
    "callbacks.append(CLR(get_lr_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWzyB_UAQrd9"
   },
   "outputs": [],
   "source": [
    "# compilo modello\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "vqa_model.compile(optimizer=\"Adam\",\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Krk3f-Senbxc"
   },
   "outputs": [],
   "source": [
    "#---------- fit modello ---------------------------------------------------\n",
    "EP = 15\n",
    "\n",
    "LUT_STD = [(0, 1e-6),\n",
    "           (2, 1e-6),\n",
    "           (8, 1e-6)]\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vqa_model.fit(x=training_generator,\n",
    "              validation_data=validation_generator,\n",
    "              epochs=EP,\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6HyD2zkQrd-"
   },
   "outputs": [],
   "source": [
    "#------------- salvo pesi --------------------------------------------------\n",
    "save_weights = True\n",
    "\n",
    "if save_weights:\n",
    "    model_name = \"VQA\"\n",
    "    model_dir = os.path.join(cwd, 'model')\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)    \n",
    "    vqa_model.save_weights(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZdH8O4zQrd_"
   },
   "outputs": [],
   "source": [
    "# faccio predizioni\n",
    "pred = vqa_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZkHG6ewnev2"
   },
   "outputs": [],
   "source": [
    "# creo csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(str(key) + ',' + str(value) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(len(pred)):\n",
    "    results[test_questionsID[i]] = np.argmax(pred[i])\n",
    "    \n",
    "create_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "polentarutti.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
